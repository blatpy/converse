{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Essentials\n",
    "### 1.1 Libraries\n",
    "\n",
    "Setting up the library is as simple as importing the Conversation object, along with the progress bar utility. [tqdm](https://tqdm.github.io/) is a kickass progressbar library for python with jupyter support, and you can see I'm importing the notebook version instead of the regular one. Replace with ```from tqdm import tqdm``` if you're executing on terminal.\n",
    "\n",
    "Note: I'm importing the necessary libraries as I need in the notebook (instead of clustering all imports at the top even though it physically hurts not to) so you can choose not to use them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from converse import Conversation\n",
    "from tqdm import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Creating a new Conversation\n",
    "\n",
    "Creating a new conversation is as simple are creating the conversation object and using the load function to add json messages. The load function can be called multiple times, and we'll cover loading multiple conversations later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "janes = Conversation() \n",
    "janes.load(\"Sample_Convo/message.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```messages``` object contains the plain JSON of all the messages loaded into the object, and this is directly accessible for additional flexibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Loaded %d messages\" % (len(janes.messages))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Exporting conversations\n",
    "\n",
    "Conversations can be exported in three main ways: as plain JSON, a [pandas](https://pandas.pydata.org/) DataFrame, or as a unicode CSV. All three are shown below: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "pd.set_option('display.max_rows', 10000)\n",
    "janes.save_csv_utf8(\"test.csv\")\n",
    "print json.dumps(janes.messages)[:100]\n",
    "janes.get_df()[:1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Sentiment Analysis\n",
    "\n",
    "Sentiment analysis is being done using the [TextBlob](https://textblob.readthedocs.io/en/dev/) library. The ```get_sentiment``` function can be used to test functionality, and modified to add possible edge cases or plug in other libraries. As we can see below, it works most of the time but it's not really perfect.\n",
    "\n",
    "Note: A subjectivity score is provided by the library, and while this is added to the data in the object, it's not really used for anything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print janes.get_sentiment(\"This is awesome!\")\n",
    "print janes.get_sentiment(\"DC movies are bad\")\n",
    "print janes.get_sentiment(\"Tony, I don't feel so good\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting\n",
    "\n",
    "### 2.1 Plotting out of the box with plotly and jupyter\n",
    "\n",
    "Jupyter and plotly make it quite simple to create interactive plots with very little code using the object. I'm using plotly offline here, and since plotly is installed as one of the dependencies this should work right away, but you can replace it with the version of your choice. Using the online plotting library (if you have an account) makes your plots instantly shareable, and using ```plot``` instead of ```iplot``` exports the plots as an easily embeddable HTML plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(janes.plot())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Custom plotting\n",
    "\n",
    "The default options are set to a single-day window, and a 10-day moving average computed across the single-day data. Let's change some of the options. For example, say you wanted a weekly window, with 1, 4 and 52 week moving averages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(janes.plot(timeframe=\"W\",smas=[1,4,52]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! The plotting is based on how stock market data is current plotted, as the next step for the library is to see if TA or Harmonic Analysis will provide some insights. Is an OHLC available? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(janes.plot(ohlc=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You bet! The OHLC colors can be further customized, and a lot more configuration is available. For details, consult the full documentation. For now, let's move on.\n",
    "\n",
    "## 3. Filters\n",
    "\n",
    "### 3.1 Multiple conversations\n",
    "\n",
    "The same Conversation object can handle as many conversations as you'd like. We can do this by simply calling ```load``` multiple times. In fact, we can load every conversation I've ever had!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moreconvos = Conversation()\n",
    "for filename in tqdm(glob(\"*/message.json\")):\n",
    "    moreconvos.load(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print len(moreconvos.messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a total of 847 conversations and 83,392 messages! We've seen how the sentiment analysis libraries can sometimes give unpredictable results before. In the library, we have two ways of combating this: averages and comparison. By taking averages of larger units of time we hope to remove some of the noise caused by incorrect prediction, and by comparing two conversations, we hope to see differences while assuming the same baseline of noise.\n",
    "\n",
    "Let's look at the columns in the dataframe once again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moreconvos.get_df().columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two stored attributes that should help us differentiate between conversations. The first is ```tag```, which is the title of the conversation. The second is ```participants```, which is a json of the participants involved in the conversation. It is worth noting that the tag can be modified during the loading process, which is sometimes necessary as the conversations can be deleted or not contain valid titles.\n",
    "\n",
    "### 3.2 Sets\n",
    "\n",
    "The first part of looking at the conversation is looking at who was talking, and which conversations have been loaded. We can do this as follows (once again, I've masked most for anonymity):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moreconvos.get_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```get_names``` function returns a python set of all unique participants in the object. The ```get_tags``` function works similarly. A fuzzy search function is also provided, if you'd like to select similar names (or don't know exactly who you're searching for):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "moreconvos.search_names(\"Jane Doe\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ```search_names``` function returns all names as a list in decreasing likelihood of match. Inverted first and last names as well as family members can be found easier this way, especially if you talk to a lot of people (not as much of a problem for me).\n",
    "\n",
    "### 3.3 Filters\n",
    "\n",
    "Once we know what we're looking for, we can start narrowing the selection using filters. The following filters are provided:\n",
    "\n",
    "1. filter_by_name(names)\n",
    "2. filter_by_tag(tags)\n",
    "3. filter_by_datetime(start, end)\n",
    "4. filter_by_timestamp(start, end)\n",
    "5. filter_by_sentiment(begin, end)\n",
    "\n",
    "All the functions have an optional ```including``` parameter, that can be set to choose for a range outside or inside the selected parameters. The functions treat the object as immutable, and return a new object with the messages that fall within the filter.\n",
    "\n",
    "For example, let's consider the weekly graph for my conversation from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(janes.plot(timeframe=\"W\",smas=[4,52]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say I want to focus in on my conversation with Jay for the period from July 14 to October 13, 2017. It looks like a significant chunk for some reason. To do this, I'd first select for my conversations with Jay, and then filter based on time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\") \\\n",
    "    .filter_by_datetime(datetime(2017,7,14), datetime(2017,10,13)) \\\n",
    "    .plot(timeframe=\"W\",smas=[4,52]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This way, we can chain multiple filters to get the exact results we want, or store intermediate objects to speed things up.\n",
    "\n",
    "### 3.4 Combining plots\n",
    "\n",
    "Next, let's try comparing how my conversations went in that particular period by plotting Jay against everyone else. Since we're still returning plotly objects, combining plots is as simple as using the ```+``` operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jay_plot = moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\") \\\n",
    "    .filter_by_datetime(datetime(2017,7,14), datetime(2017,10,13)) \\\n",
    "    .plot(timeframe=\"W\",smas=[4],label=\"Jay\")\n",
    "    \n",
    "everyone_else_plot = moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\", including=False) \\\n",
    "    .filter_by_datetime(datetime(2017,7,14), datetime(2017,10,13)) \\\n",
    "    .plot(timeframe=\"W\",smas=[4],label=\"Everyone Else\")\n",
    "    \n",
    "iplot(jay_plot+everyone_else_plot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kind of analysis can be powerful in showing general trends across time against personal volatility. As we can see, Jay tends to run quite a bit happier than the total average - by a lot.\n",
    "\n",
    "### 3.5 Annotations and Density plots\n",
    "\n",
    "So far we've looked at charts of sentiment scores plotted on average. However, the astute will have noticed that it's quite hard to track down which messages contributed to which scores, and how this changes across time. In addition, since messages are usually sporadic, it would be helpful to see how many messages contributed to a particular average, since fewer messages can lead to a more volatile average score, even with consistent windows.\n",
    "\n",
    "To this purpose, the plotting function has a density option:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\") \\\n",
    "    .plot(timeframe=\"W\",smas=[4],label=\"Jane Doe\",density=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The density function provides useful information in telling us how frequently we were talking to each other, as well as providing some explanation for the more volatile values. The density plot is provided for each SMA being added to the graph.\n",
    "\n",
    "In addition, there is the option to annotate each data point with information that would be valuable. For this purpose, two annotation functions are provided:\n",
    "\n",
    "* ```annot_highlow``` annotates each average value with the current message as well as the highest and lowest scoring messages within that window.\n",
    "* ```annot_current_with_subjectivity``` provides annotations that show the exact sentiment score of the current message as well as the subjectivity score.\n",
    "\n",
    "The functions follow the same format (which can be found in the documentation), and allow for custom functions to be plugged in which provide other useful pieces of information. The two functions are demonstrated below (for purposes of anonymity, I've had to replace the actual plots with images):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\") \\\n",
    "    .plot(timeframe=\"W\",smas=[4],label=\"Jane Doe\",annotation=janes.annot_highlow))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "iplot(moreconvos \\\n",
    "    .filter_by_name(\"Jane Doe\") \\\n",
    "    .plot(timeframe=\"W\",smas=[4],label=\"Jane Doe\",annotation=janes.annot_current_with_subjectivity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's it! Oh, and the ```get_stats``` function provides a JSON with all the basic information about the object."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
